{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d01665",
   "metadata": {},
   "source": [
    "# Advanced 2-Stage ML (Target: 0.40+)\n",
    "\n",
    "**전략:**\n",
    "1. Feature 확장: 13개 → 35개\n",
    "2. Multi-Model: XGBoost + LightGBM + CatBoost\n",
    "3. Multiple Thresholds: 0.28, 0.30, 0.32, 0.34, 0.36\n",
    "4. Meta-Ensemble: Stacking\n",
    "\n",
    "**현재 Best: 0.3513**\n",
    "**목표: 0.40+**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb6c75",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14404d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup 완료 - Advanced Features 모드\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "PAIR_MAX_LAG = 7\n",
    "PAIR_MIN_NONZERO = 8\n",
    "VAL_MIN_NONZERO = 2\n",
    "\n",
    "PAIR_LABEL_CORR_THRESHOLD = 0.32\n",
    "VAL_GT_CORR_THRESHOLD = 0.25\n",
    "\n",
    "NEG_POS_RATIO = 1.5\n",
    "PAIR_TOP_K = 3000\n",
    "\n",
    "TRAIN_END_STR = \"2024-12-01\"\n",
    "VAL_START_STR = \"2025-01-01\"\n",
    "VAL_END_STR = \"2025-04-01\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(\"Setup 완료 - Advanced Features 모드\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea36a6",
   "metadata": {},
   "source": [
    "## 2. 유틸 함수 (기존 + 확장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e18f8a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 유틸 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "def safe_corr(a, b):\n",
    "    mask = (~np.isnan(a)) & (~np.isnan(b))\n",
    "    if mask.sum() < 3:\n",
    "        return 0.0\n",
    "    aa, bb = a[mask], b[mask]\n",
    "    if np.std(aa) == 0 or np.std(bb) == 0:\n",
    "        return 0.0\n",
    "    return float(np.corrcoef(aa, bb)[0, 1])\n",
    "\n",
    "def load_pivot(train_path=\"train.csv\"):\n",
    "    df = pd.read_csv(train_path)\n",
    "    monthly = df.groupby([\"item_id\", \"year\", \"month\"], as_index=False)[\"value\"].sum()\n",
    "    monthly[\"ym\"] = pd.to_datetime(\n",
    "        monthly[\"year\"].astype(str) + \"-\" + monthly[\"month\"].astype(str).str.zfill(2) + \"-01\"\n",
    "    )\n",
    "    pivot = monthly.pivot(index=\"item_id\", columns=\"ym\", values=\"value\")\n",
    "    pivot = pivot.fillna(0).sort_index(axis=1)\n",
    "    print(\"pivot shape:\", pivot.shape)\n",
    "    return pivot, df\n",
    "\n",
    "def get_time_indices(pivot):\n",
    "    months = list(pivot.columns)\n",
    "    month_to_idx = {m: i for i, m in enumerate(months)}\n",
    "    train_end = pd.to_datetime(TRAIN_END_STR)\n",
    "    val_start = pd.to_datetime(VAL_START_STR)\n",
    "    val_end = pd.to_datetime(VAL_END_STR)\n",
    "    return (months, month_to_idx[train_end], month_to_idx[val_start], month_to_idx[val_end])\n",
    "\n",
    "print(\"기본 유틸 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6600df",
   "metadata": {},
   "source": [
    "## 3. Advanced Feature 생성 (35+ features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcee4986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced feature 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "def build_advanced_pair_features(pivot, upto_idx, max_lag=7, min_nonzero=8,\n",
    "                                  corr_threshold_for_label=0.30, neg_pos_ratio=2.0):\n",
    "    \"\"\"35+ features로 확장된 pair feature matrix\"\"\"\n",
    "    items = pivot.index.to_list()\n",
    "    months = list(pivot.columns)\n",
    "    \n",
    "    sub_cols = months[:upto_idx + 1]\n",
    "    pivot_sub = pivot[sub_cols]\n",
    "    n_sub_months = pivot_sub.shape[1]\n",
    "    \n",
    "    rows_pos = []\n",
    "    rows_neg = []\n",
    "    \n",
    "    for leader in tqdm(items, desc=\"build_advanced_features\"):\n",
    "        a = pivot_sub.loc[leader].values.astype(float)\n",
    "        if np.count_nonzero(a) < min_nonzero:\n",
    "            continue\n",
    "        \n",
    "        for follower in items:\n",
    "            if leader == follower:\n",
    "                continue\n",
    "            \n",
    "            b = pivot_sub.loc[follower].values.astype(float)\n",
    "            if np.count_nonzero(b) < min_nonzero:\n",
    "                continue\n",
    "            \n",
    "            # Lag별 correlation 계산\n",
    "            lag_corrs = []\n",
    "            best_corr = 0.0\n",
    "            second_corr = 0.0\n",
    "            third_corr = 0.0\n",
    "            best_lag = None\n",
    "            \n",
    "            for lag in range(1, max_lag + 1):\n",
    "                if n_sub_months <= lag:\n",
    "                    lag_corrs.append(0.0)\n",
    "                    continue\n",
    "                \n",
    "                c = safe_corr(a[:-lag], b[lag:])\n",
    "                lag_corrs.append(c)\n",
    "                \n",
    "                if abs(c) > abs(best_corr):\n",
    "                    third_corr = second_corr\n",
    "                    second_corr = best_corr\n",
    "                    best_corr = c\n",
    "                    best_lag = lag\n",
    "                elif abs(c) > abs(second_corr):\n",
    "                    third_corr = second_corr\n",
    "                    second_corr = c\n",
    "                elif abs(c) > abs(third_corr):\n",
    "                    third_corr = c\n",
    "            \n",
    "            if best_lag is None:\n",
    "                continue\n",
    "            \n",
    "            lag_corrs = np.array(lag_corrs, dtype=float)\n",
    "            \n",
    "            # Rolling statistics for a and b\n",
    "            a_rolling_3 = np.array([np.mean(a[max(0, i-2):i+1]) for i in range(len(a))])\n",
    "            b_rolling_3 = np.array([np.mean(b[max(0, i-2):i+1]) for i in range(len(b))])\n",
    "            a_rolling_6 = np.array([np.mean(a[max(0, i-5):i+1]) for i in range(len(a))])\n",
    "            b_rolling_6 = np.array([np.mean(b[max(0, i-5):i+1]) for i in range(len(b))])\n",
    "            \n",
    "            # Trend features\n",
    "            a_trend = (a[-1] - a[0]) / (len(a) + 1) if len(a) > 1 else 0\n",
    "            b_trend = (b[-1] - b[0]) / (len(b) + 1) if len(b) > 1 else 0\n",
    "            \n",
    "            feats = {\n",
    "                \"leading_item_id\": leader,\n",
    "                \"following_item_id\": follower,\n",
    "                \n",
    "                # 기존 features (11개)\n",
    "                \"max_corr\": float(best_corr),\n",
    "                \"best_lag\": int(best_lag),\n",
    "                \"second_corr\": float(second_corr),\n",
    "                \"third_corr\": float(third_corr),\n",
    "                \"corr_stability\": float(abs(best_corr - second_corr)),\n",
    "                \"corr_mean\": float(np.mean(lag_corrs)),\n",
    "                \"corr_std\": float(np.std(lag_corrs)),\n",
    "                \"corr_abs_mean\": float(np.mean(np.abs(lag_corrs))),\n",
    "                \"nonzero_a\": int(np.count_nonzero(a)),\n",
    "                \"nonzero_b\": int(np.count_nonzero(b)),\n",
    "                \"sum_a\": float(a.sum()),\n",
    "                \"sum_b\": float(b.sum()),\n",
    "                \n",
    "                # Lag별 개별 correlation (7개)\n",
    "                \"lag1_corr\": float(lag_corrs[0]) if len(lag_corrs) > 0 else 0.0,\n",
    "                \"lag2_corr\": float(lag_corrs[1]) if len(lag_corrs) > 1 else 0.0,\n",
    "                \"lag3_corr\": float(lag_corrs[2]) if len(lag_corrs) > 2 else 0.0,\n",
    "                \"lag4_corr\": float(lag_corrs[3]) if len(lag_corrs) > 3 else 0.0,\n",
    "                \"lag5_corr\": float(lag_corrs[4]) if len(lag_corrs) > 4 else 0.0,\n",
    "                \"lag6_corr\": float(lag_corrs[5]) if len(lag_corrs) > 5 else 0.0,\n",
    "                \"lag7_corr\": float(lag_corrs[6]) if len(lag_corrs) > 6 else 0.0,\n",
    "                \n",
    "                # Rolling statistics (8개)\n",
    "                \"a_rolling3_mean\": float(np.mean(a_rolling_3)),\n",
    "                \"a_rolling3_std\": float(np.std(a_rolling_3)),\n",
    "                \"b_rolling3_mean\": float(np.mean(b_rolling_3)),\n",
    "                \"b_rolling3_std\": float(np.std(b_rolling_3)),\n",
    "                \"a_rolling6_mean\": float(np.mean(a_rolling_6)),\n",
    "                \"a_rolling6_std\": float(np.std(a_rolling_6)),\n",
    "                \"b_rolling6_mean\": float(np.mean(b_rolling_6)),\n",
    "                \"b_rolling6_std\": float(np.std(b_rolling_6)),\n",
    "                \n",
    "                # Trend features (4개)\n",
    "                \"a_trend\": float(a_trend),\n",
    "                \"b_trend\": float(b_trend),\n",
    "                \"trend_ratio\": float(b_trend / (abs(a_trend) + 1e-6)),\n",
    "                \"trend_diff\": float(abs(b_trend - a_trend)),\n",
    "                \n",
    "                # Interaction features (5개)\n",
    "                \"ab_ratio\": float(b.sum() / (a.sum() + 1)),\n",
    "                \"ab_corr_recent\": float(safe_corr(a[-6:], b[-6:])),\n",
    "                \"max_min_ratio_a\": float(a.max() / (a.min() + 1)),\n",
    "                \"max_min_ratio_b\": float(b.max() / (b.min() + 1)),\n",
    "                \"corr_weighted\": float(np.average(np.abs(lag_corrs), weights=range(len(lag_corrs), 0, -1))),\n",
    "            }\n",
    "            \n",
    "            label = 1 if abs(best_corr) >= corr_threshold_for_label else 0\n",
    "            \n",
    "            if label == 1:\n",
    "                rows_pos.append({**feats, \"label\": 1})\n",
    "            else:\n",
    "                rows_neg.append({**feats, \"label\": 0})\n",
    "    \n",
    "    df_pos = pd.DataFrame(rows_pos)\n",
    "    df_neg = pd.DataFrame(rows_neg)\n",
    "    print(f\"pos pairs: {df_pos.shape}, neg pairs: {df_neg.shape}\")\n",
    "    \n",
    "    if df_pos.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    n_pos = len(df_pos)\n",
    "    n_neg_keep = int(neg_pos_ratio * n_pos)\n",
    "    if len(df_neg) > n_neg_keep:\n",
    "        df_neg = df_neg.sample(n_neg_keep, random_state=RANDOM_SEED)\n",
    "    \n",
    "    df_all = pd.concat([df_pos, df_neg], axis=0).reset_index(drop=True)\n",
    "    print(f\"Total features: {len([c for c in df_all.columns if c not in ['leading_item_id', 'following_item_id', 'label']])}\")\n",
    "    return df_all\n",
    "\n",
    "print(\"Advanced feature 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a71873",
   "metadata": {},
   "source": [
    "## 4. Multi-Model Classifier (XGB + LightGBM + CatBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f57f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-model classifier 함수 정의 완료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_multi_model_classifier(df_pairs):\n",
    "    \"\"\"3개 모델로 앙상블 Classifier\"\"\"\n",
    "    # Feature columns 추출\n",
    "    feature_cols = [c for c in df_pairs.columns if c not in ['leading_item_id', 'following_item_id', 'label']]\n",
    "    \n",
    "    df = df_pairs.copy()\n",
    "    df[feature_cols] = df[feature_cols].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    X = df[feature_cols].values\n",
    "    y = df[\"label\"].values\n",
    "    \n",
    "    print(f\"Training on {len(feature_cols)} features...\")\n",
    "    \n",
    "    # XGBoost\n",
    "    clf_xgb = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        reg_alpha=0.3,\n",
    "        reg_lambda=0.8,\n",
    "        min_child_weight=2,\n",
    "        gamma=0.1,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "    clf_xgb.fit(X, y)\n",
    "    print(\"XGBoost trained\")\n",
    "    \n",
    "    # LightGBM\n",
    "    clf_lgb = LGBMClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        reg_alpha=0.3,\n",
    "        reg_lambda=0.8,\n",
    "        min_child_samples=20,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    clf_lgb.fit(X, y)\n",
    "    print(\"LightGBM trained\")\n",
    "    \n",
    "    # CatBoost\n",
    "    clf_cat = CatBoostClassifier(\n",
    "        iterations=300,\n",
    "        depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        reg_lambda=0.8,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        verbose=0\n",
    "    )\n",
    "    clf_cat.fit(X, y)\n",
    "    print(\"CatBoost trained\")\n",
    "    \n",
    "    return [clf_xgb, clf_lgb, clf_cat], feature_cols\n",
    "\n",
    "print(\"Multi-model classifier 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42b4c3",
   "metadata": {},
   "source": [
    "## 5. Advanced Pair Scoring (Ensemble 예측)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6572fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced scoring 함수 정의 완료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def score_all_pairs_advanced(pivot, classifiers, feature_cols, max_lag=7, min_nonzero=8):\n",
    "    \"\"\"Advanced features + Multi-model ensemble로 모든 쌍 scoring\"\"\"\n",
    "    items = pivot.index.to_list()\n",
    "    months = list(pivot.columns)\n",
    "    n_months = len(months)\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    for leader in tqdm(items, desc=\"score_all_pairs_advanced\"):\n",
    "        a = pivot.loc[leader].values.astype(float)\n",
    "        if np.count_nonzero(a) < min_nonzero:\n",
    "            continue\n",
    "        \n",
    "        for follower in items:\n",
    "            if leader == follower:\n",
    "                continue\n",
    "            \n",
    "            b = pivot.loc[follower].values.astype(float)\n",
    "            if np.count_nonzero(b) < min_nonzero:\n",
    "                continue\n",
    "            \n",
    "            # Lag별 correlation\n",
    "            lag_corrs = []\n",
    "            best_corr = 0.0\n",
    "            second_corr = 0.0\n",
    "            third_corr = 0.0\n",
    "            best_lag = None\n",
    "            \n",
    "            for lag in range(1, max_lag + 1):\n",
    "                if n_months <= lag:\n",
    "                    lag_corrs.append(0.0)\n",
    "                    continue\n",
    "                \n",
    "                c = safe_corr(a[:-lag], b[lag:])\n",
    "                lag_corrs.append(c)\n",
    "                \n",
    "                if abs(c) > abs(best_corr):\n",
    "                    third_corr = second_corr\n",
    "                    second_corr = best_corr\n",
    "                    best_corr = c\n",
    "                    best_lag = lag\n",
    "                elif abs(c) > abs(second_corr):\n",
    "                    third_corr = second_corr\n",
    "                    second_corr = c\n",
    "                elif abs(c) > abs(third_corr):\n",
    "                    third_corr = c\n",
    "            \n",
    "            if best_lag is None:\n",
    "                continue\n",
    "            \n",
    "            lag_corrs = np.array(lag_corrs, dtype=float)\n",
    "            \n",
    "            # Rolling statistics\n",
    "            a_rolling_3 = np.array([np.mean(a[max(0, i-2):i+1]) for i in range(len(a))])\n",
    "            b_rolling_3 = np.array([np.mean(b[max(0, i-2):i+1]) for i in range(len(b))])\n",
    "            a_rolling_6 = np.array([np.mean(a[max(0, i-5):i+1]) for i in range(len(a))])\n",
    "            b_rolling_6 = np.array([np.mean(b[max(0, i-5):i+1]) for i in range(len(b))])\n",
    "            \n",
    "            a_trend = (a[-1] - a[0]) / (len(a) + 1) if len(a) > 1 else 0\n",
    "            b_trend = (b[-1] - b[0]) / (len(b) + 1) if len(b) > 1 else 0\n",
    "            \n",
    "            # Feature dictionary\n",
    "            feats = {\n",
    "                \"max_corr\": float(best_corr),\n",
    "                \"best_lag\": int(best_lag),\n",
    "                \"second_corr\": float(second_corr),\n",
    "                \"third_corr\": float(third_corr),\n",
    "                \"corr_stability\": float(abs(best_corr - second_corr)),\n",
    "                \"corr_mean\": float(np.mean(lag_corrs)),\n",
    "                \"corr_std\": float(np.std(lag_corrs)),\n",
    "                \"corr_abs_mean\": float(np.mean(np.abs(lag_corrs))),\n",
    "                \"nonzero_a\": int(np.count_nonzero(a)),\n",
    "                \"nonzero_b\": int(np.count_nonzero(b)),\n",
    "                \"sum_a\": float(a.sum()),\n",
    "                \"sum_b\": float(b.sum()),\n",
    "                \"lag1_corr\": float(lag_corrs[0]) if len(lag_corrs) > 0 else 0.0,\n",
    "                \"lag2_corr\": float(lag_corrs[1]) if len(lag_corrs) > 1 else 0.0,\n",
    "                \"lag3_corr\": float(lag_corrs[2]) if len(lag_corrs) > 2 else 0.0,\n",
    "                \"lag4_corr\": float(lag_corrs[3]) if len(lag_corrs) > 3 else 0.0,\n",
    "                \"lag5_corr\": float(lag_corrs[4]) if len(lag_corrs) > 4 else 0.0,\n",
    "                \"lag6_corr\": float(lag_corrs[5]) if len(lag_corrs) > 5 else 0.0,\n",
    "                \"lag7_corr\": float(lag_corrs[6]) if len(lag_corrs) > 6 else 0.0,\n",
    "                \"a_rolling3_mean\": float(np.mean(a_rolling_3)),\n",
    "                \"a_rolling3_std\": float(np.std(a_rolling_3)),\n",
    "                \"b_rolling3_mean\": float(np.mean(b_rolling_3)),\n",
    "                \"b_rolling3_std\": float(np.std(b_rolling_3)),\n",
    "                \"a_rolling6_mean\": float(np.mean(a_rolling_6)),\n",
    "                \"a_rolling6_std\": float(np.std(a_rolling_6)),\n",
    "                \"b_rolling6_mean\": float(np.mean(b_rolling_6)),\n",
    "                \"b_rolling6_std\": float(np.std(b_rolling_6)),\n",
    "                \"a_trend\": float(a_trend),\n",
    "                \"b_trend\": float(b_trend),\n",
    "                \"trend_ratio\": float(b_trend / (abs(a_trend) + 1e-6)),\n",
    "                \"trend_diff\": float(abs(b_trend - a_trend)),\n",
    "                \"ab_ratio\": float(b.sum() / (a.sum() + 1)),\n",
    "                \"ab_corr_recent\": float(safe_corr(a[-6:], b[-6:])),\n",
    "                \"max_min_ratio_a\": float(a.max() / (a.min() + 1)),\n",
    "                \"max_min_ratio_b\": float(b.max() / (b.min() + 1)),\n",
    "                \"corr_weighted\": float(np.average(np.abs(lag_corrs), weights=range(len(lag_corrs), 0, -1))),\n",
    "            }\n",
    "            \n",
    "            # Ensemble prediction (평균)\n",
    "            x_vec = np.array([[feats[col] for col in feature_cols]], dtype=float)\n",
    "            probs = []\n",
    "            for clf in classifiers:\n",
    "                prob = float(clf.predict_proba(x_vec)[0, 1])\n",
    "                probs.append(prob)\n",
    "            \n",
    "            ensemble_prob = np.mean(probs)\n",
    "            \n",
    "            rows.append({\n",
    "                \"leading_item_id\": leader,\n",
    "                \"following_item_id\": follower,\n",
    "                \"best_lag\": int(best_lag),\n",
    "                \"max_corr\": float(best_corr),\n",
    "                \"corr_stability\": float(abs(best_corr - second_corr)),\n",
    "                \"clf_prob\": ensemble_prob\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "print(\"Advanced scoring 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c034114",
   "metadata": {},
   "source": [
    "## 6. Advanced Regression Dataset (30+ features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6edfc93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced regression dataset 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "def build_advanced_regression_dataset(pivot, pairs, target_start_idx, target_end_idx):\n",
    "    \"\"\"30+ features로 확장된 regression dataset\"\"\"\n",
    "    months = list(pivot.columns)\n",
    "    n_months = len(months)\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    for row in tqdm(pairs.itertuples(index=False), desc=\"build_regression_dataset\"):\n",
    "        leader = row.leading_item_id\n",
    "        follower = row.following_item_id\n",
    "        lag = int(row.best_lag)\n",
    "        \n",
    "        a = pivot.loc[leader].values.astype(float)\n",
    "        b = pivot.loc[follower].values.astype(float)\n",
    "        \n",
    "        for t in range(lag + 2, n_months - 1):\n",
    "            target_idx = t + 1\n",
    "            if target_idx < target_start_idx or target_idx > target_end_idx:\n",
    "                continue\n",
    "            \n",
    "            if t - 2 < 0 or (t - lag - 1) < 0:\n",
    "                continue\n",
    "            \n",
    "            # 기본 features\n",
    "            b_t = b[t]\n",
    "            b_t_1 = b[t - 1]\n",
    "            b_t_2 = b[t - 2]\n",
    "            a_t_lag = a[t - lag]\n",
    "            a_t_lag_1 = a[t - lag - 1]\n",
    "            \n",
    "            b_ma3 = np.mean([b_t, b_t_1, b_t_2])\n",
    "            if (t - lag - 2) >= 0:\n",
    "                a_ma3 = np.mean([a_t_lag, a_t_lag_1, a[t - lag - 2]])\n",
    "            else:\n",
    "                a_ma3 = np.mean([a_t_lag, a_t_lag_1])\n",
    "            \n",
    "            b_change = (b_t - b_t_1) / (b_t_1 + 1)\n",
    "            a_change = (a_t_lag - a_t_lag_1) / (a_t_lag_1 + 1)\n",
    "            ab_ratio = b_t / (a_t_lag + 1)\n",
    "            \n",
    "            # Rolling features (더 많은 window)\n",
    "            b_ma6 = np.mean(b[max(0, t-5):t+1]) if t >= 5 else np.mean(b[:t+1])\n",
    "            a_ma6 = np.mean(a[max(0, t-lag-5):t-lag+1]) if t-lag >= 5 else np.mean(a[:t-lag+1])\n",
    "            \n",
    "            b_std3 = np.std([b_t, b_t_1, b_t_2])\n",
    "            a_std3 = np.std([a_t_lag, a_t_lag_1]) if (t - lag - 2) < 0 else np.std([a_t_lag, a_t_lag_1, a[t - lag - 2]])\n",
    "            \n",
    "            # Trend features\n",
    "            b_recent_trend = (b_t - b_t_2) / 2 if b_t_2 != 0 else 0\n",
    "            a_recent_trend = (a_t_lag - a_t_lag_1) if a_t_lag_1 != 0 else 0\n",
    "            \n",
    "            # Acceleration\n",
    "            b_accel = (b_t - b_t_1) - (b_t_1 - b_t_2) if b_t_2 != 0 else 0\n",
    "            \n",
    "            # Max/Min ratio\n",
    "            b_max_recent = max(b[max(0, t-5):t+1])\n",
    "            b_min_recent = min(b[max(0, t-5):t+1]) + 1\n",
    "            b_max_min_ratio = b_max_recent / b_min_recent\n",
    "            \n",
    "            # Volatility\n",
    "            b_volatility = np.std(b[max(0, t-5):t+1]) / (np.mean(b[max(0, t-5):t+1]) + 1)\n",
    "            \n",
    "            target = b[target_idx]\n",
    "            \n",
    "            rows.append({\n",
    "                \"leading_item_id\": leader,\n",
    "                \"following_item_id\": follower,\n",
    "                \n",
    "                # 기존 13개\n",
    "                \"b_t\": b_t,\n",
    "                \"b_t_1\": b_t_1,\n",
    "                \"b_t_2\": b_t_2,\n",
    "                \"b_ma3\": b_ma3,\n",
    "                \"b_change\": b_change,\n",
    "                \"a_t_lag\": a_t_lag,\n",
    "                \"a_t_lag_1\": a_t_lag_1,\n",
    "                \"a_ma3\": a_ma3,\n",
    "                \"a_change\": a_change,\n",
    "                \"ab_value_ratio\": ab_ratio,\n",
    "                \"max_corr\": row.max_corr,\n",
    "                \"best_lag\": lag,\n",
    "                \"corr_stability\": row.corr_stability,\n",
    "                \n",
    "                # 새로운 features (17개)\n",
    "                \"b_ma6\": b_ma6,\n",
    "                \"a_ma6\": a_ma6,\n",
    "                \"b_std3\": b_std3,\n",
    "                \"a_std3\": a_std3,\n",
    "                \"b_recent_trend\": b_recent_trend,\n",
    "                \"a_recent_trend\": a_recent_trend,\n",
    "                \"b_accel\": b_accel,\n",
    "                \"b_max_min_ratio\": b_max_min_ratio,\n",
    "                \"b_volatility\": b_volatility,\n",
    "                \"ab_ma_ratio\": b_ma3 / (a_ma3 + 1),\n",
    "                \"ab_change_ratio\": b_change / (abs(a_change) + 1e-6),\n",
    "                \"b_momentum\": b_t / (b_ma3 + 1),\n",
    "                \"a_momentum\": a_t_lag / (a_ma3 + 1),\n",
    "                \"cross_momentum\": (b_t / (b_ma3 + 1)) * (a_t_lag / (a_ma3 + 1)),\n",
    "                \"b_relative_pos\": (b_t - b_min_recent) / (b_max_recent - b_min_recent + 1),\n",
    "                \"trend_alignment\": b_recent_trend * a_recent_trend,\n",
    "                \"value_gap\": abs(b_t - a_t_lag),\n",
    "                \n",
    "                \"target\": target,\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    print(f\"Regression dataset: {df.shape}, features: {len([c for c in df.columns if c not in ['leading_item_id', 'following_item_id', 'target']])}\")\n",
    "    return df\n",
    "\n",
    "print(\"Advanced regression dataset 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32d2091",
   "metadata": {},
   "source": [
    "## 7. Multi-Model Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4bd6e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-model regressor 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "def train_multi_model_regressor(df_train):\n",
    "    \"\"\"XGB + LightGBM + CatBoost 앙상블 Regressor\"\"\"\n",
    "    feature_cols = [c for c in df_train.columns if c not in ['leading_item_id', 'following_item_id', 'target']]\n",
    "    \n",
    "    df_train = df_train.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    X = df_train[feature_cols].values\n",
    "    y = df_train[\"target\"].values\n",
    "    \n",
    "    print(f\"Training regressors on {len(feature_cols)} features...\")\n",
    "    \n",
    "    # XGBoost\n",
    "    reg_xgb = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.1,\n",
    "        reg_alpha=0.3,\n",
    "        reg_lambda=0.8,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    reg_xgb.fit(X, y)\n",
    "    print(\"XGBoost regressor trained\")\n",
    "    \n",
    "    # LightGBM\n",
    "    reg_lgb = LGBMRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        reg_alpha=0.3,\n",
    "        reg_lambda=0.8,\n",
    "        min_child_samples=20,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    reg_lgb.fit(X, y)\n",
    "    print(\"LightGBM regressor trained\")\n",
    "    \n",
    "    # CatBoost\n",
    "    reg_cat = CatBoostRegressor(\n",
    "        iterations=300,\n",
    "        depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        reg_lambda=0.8,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        verbose=0\n",
    "    )\n",
    "    reg_cat.fit(X, y)\n",
    "    print(\"CatBoost regressor trained\")\n",
    "    \n",
    "    return [reg_xgb, reg_lgb, reg_cat], feature_cols\n",
    "\n",
    "print(\"Multi-model regressor 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3968b1",
   "metadata": {},
   "source": [
    "## 8. 실행 및 Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01b4e2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pivot shape: (100, 43)\n",
      "Train end: 35, Val: 36-39\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "pivot, raw = load_pivot(\"train.csv\")\n",
    "months, train_end_idx, val_start_idx, val_end_idx = get_time_indices(pivot)\n",
    "print(f\"Train end: {train_end_idx}, Val: {val_start_idx}-{val_end_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9565df4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building advanced pair features...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_advanced_features: 100%|██████████| 100/100 [00:37<00:00,  2.69it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos pairs: (3865, 39), neg pairs: (4507, 39)\n",
      "Total features: 36\n",
      "Pair dataset: (8372, 39)\n",
      "\n",
      "Training multi-model classifier ensemble...\n",
      "Training on 36 features...\n",
      "XGBoost trained\n",
      "XGBoost trained\n",
      "LightGBM trained\n",
      "LightGBM trained\n",
      "CatBoost trained\n",
      "Classifier features: 36\n",
      "CatBoost trained\n",
      "Classifier features: 36\n"
     ]
    }
   ],
   "source": [
    "# Classifier 학습 (Advanced Features)\n",
    "print(\"Building advanced pair features...\")\n",
    "df_pairs = build_advanced_pair_features(pivot, train_end_idx, \n",
    "                                        neg_pos_ratio=1.5, \n",
    "                                        corr_threshold_for_label=0.32)\n",
    "print(f\"Pair dataset: {df_pairs.shape}\")\n",
    "\n",
    "print(\"\\nTraining multi-model classifier ensemble...\")\n",
    "classifiers, clf_cols = train_multi_model_classifier(df_pairs)\n",
    "print(f\"Classifier features: {len(clf_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e87ce98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring all pairs with multi-model ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "score_all_pairs_advanced: 100%|██████████| 100/100 [02:39<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs scored: 8556\n",
      "Top K pairs selected: 3000\n",
      "Prob range: 0.9997 - 0.9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 모든 페어 스코어링 (Multi-model ensemble)\n",
    "print(\"Scoring all pairs with multi-model ensemble...\")\n",
    "pairs_all = score_all_pairs_advanced(pivot, classifiers, clf_cols, train_end_idx)\n",
    "print(f\"Total pairs scored: {len(pairs_all)}\")\n",
    "\n",
    "# Top 3000 선택\n",
    "pairs_top = pairs_all.sort_values(\"clf_prob\", ascending=False).head(3000).copy()\n",
    "print(f\"Top K pairs selected: {len(pairs_top)}\")\n",
    "print(f\"Prob range: {pairs_top['clf_prob'].min():.4f} - {pairs_top['clf_prob'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a56a560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building advanced regression dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_regression_dataset: 3000it [00:12, 240.82it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression dataset: (21774, 33), features: 30\n",
      "Regression dataset: (21774, 33)\n",
      "\n",
      "Training multi-model regressor ensemble...\n",
      "Training regressors on 30 features...\n",
      "XGBoost regressor trained\n",
      "XGBoost regressor trained\n",
      "LightGBM regressor trained\n",
      "LightGBM regressor trained\n",
      "CatBoost regressor trained\n",
      "Regressor features: 30\n",
      "CatBoost regressor trained\n",
      "Regressor features: 30\n"
     ]
    }
   ],
   "source": [
    "# Regressor 학습 (Advanced Features)\n",
    "print(\"Building advanced regression dataset...\")\n",
    "df_train = build_advanced_regression_dataset(pivot, pairs_top, 0, train_end_idx)\n",
    "print(f\"Regression dataset: {df_train.shape}\")\n",
    "\n",
    "print(\"\\nTraining multi-model regressor ensemble...\")\n",
    "regressors, reg_cols = train_multi_model_regressor(df_train)\n",
    "print(f\"Regressor features: {len(reg_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69a30066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions with multi-model ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_regression_dataset: 3000it [00:03, 763.81it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression dataset: (10809, 33), features: 30\n",
      "Model 1 pred range: 16522.8809 - 111831136.0000\n",
      "Model 2 pred range: 12867.5175 - 115383688.6426\n",
      "Model 3 pred range: -128354.4894 - 109054335.6789\n",
      "Ensemble pred range: -6540.3101 - 109456864.1072\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['month_id', 'series_a', 'series_b'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Submission 파일 생성\u001b[39;00m\n\u001b[32m     23\u001b[39m df_test[\u001b[33m\"\u001b[39m\u001b[33mpred_b\u001b[39m\u001b[33m\"\u001b[39m] = y_pred\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m submission = \u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmonth_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseries_a\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseries_b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpred_b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n\u001b[32m     25\u001b[39m submission.columns = [\u001b[33m\"\u001b[39m\u001b[33mmonth_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mseries_a\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mseries_b\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     27\u001b[39m submission.to_csv(\u001b[33m\"\u001b[39m\u001b[33msubmission_advanced.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['month_id', 'series_a', 'series_b'] not in index\""
     ]
    }
   ],
   "source": [
    "# Submission 생성 (Multi-model ensemble predictions)\n",
    "print(\"Generating predictions with multi-model ensemble...\")\n",
    "\n",
    "# Test 데이터 생성\n",
    "df_test = build_advanced_regression_dataset(pivot, pairs_top, \n",
    "                                           train_end_idx + 1, \n",
    "                                           val_end_idx)\n",
    "\n",
    "X_test = df_test[reg_cols]\n",
    "\n",
    "# 3개 모델의 예측 평균\n",
    "preds = []\n",
    "for i, model in enumerate(regressors):\n",
    "    pred = model.predict(X_test)\n",
    "    preds.append(pred)\n",
    "    print(f\"Model {i+1} pred range: {pred.min():.4f} - {pred.max():.4f}\")\n",
    "\n",
    "# Ensemble averaging\n",
    "y_pred = np.mean(preds, axis=0)\n",
    "print(f\"Ensemble pred range: {y_pred.min():.4f} - {y_pred.max():.4f}\")\n",
    "\n",
    "# Submission 파일 생성\n",
    "df_test[\"pred_b\"] = y_pred\n",
    "submission = df_test[[\"month_id\", \"series_a\", \"series_b\", \"pred_b\"]].copy()\n",
    "submission.columns = [\"month_id\", \"series_a\", \"series_b\", \"value\"]\n",
    "\n",
    "submission.to_csv(\"submission_advanced.csv\", index=False)\n",
    "print(f\"\\n✅ Submission saved: submission_advanced.csv ({len(submission)} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f2241",
   "metadata": {},
   "source": [
    "## 9. 모델 비교 및 분석\n",
    "\n",
    "**Advanced Model 특징:**\n",
    "- Classifier: 35+ features (lag-specific, rolling, trend, interaction)\n",
    "- Regressor: 30+ features (momentum, volatility, cross features)\n",
    "- Multi-model ensemble: XGBoost + LightGBM + CatBoost\n",
    "- Ensemble averaging for robust predictions\n",
    "\n",
    "**Best Single Model (improved_model.ipynb):**\n",
    "- Score: 0.3513\n",
    "- Classifier: 13 features\n",
    "- Regressor: 13 features\n",
    "- Single XGBoost model\n",
    "\n",
    "**Expected Improvement:**\n",
    "- Feature engineering: 더 풍부한 feature set으로 패턴 포착\n",
    "- Model diversity: 3개 모델의 앙상블로 overfitting 감소\n",
    "- Target score: 0.40+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
